{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"tcs_only_modeling_abt.tsv\", sep='\\t')\n",
    "data = df.drop([\"uid\", \"tech_obs_id\", \"app_bank_nm\", \"tech_dog_type\", \"trg_utilization\", \"tech_target_source\", \"tech_target_d\"],\n",
    "               axis = 1)\n",
    "data = data.drop(['var_0{}'.format(i) for i in range(63, 73 + 1)], axis = 1)\n",
    "data = data.dropna()\n",
    "data = pd.get_dummies(data)\n",
    "y1 = data['trg_pd']\n",
    "y2 = data['trg_grace']\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data = pd.DataFrame(scaler.fit_transform(data), columns = data.columns)\n",
    "data = data.drop(columns=['trg_pd', 'trg_grace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_001</th>\n",
       "      <th>var_002</th>\n",
       "      <th>var_003</th>\n",
       "      <th>var_004</th>\n",
       "      <th>var_005</th>\n",
       "      <th>var_006</th>\n",
       "      <th>var_007</th>\n",
       "      <th>var_008</th>\n",
       "      <th>var_009</th>\n",
       "      <th>var_010</th>\n",
       "      <th>...</th>\n",
       "      <th>var_062_mts</th>\n",
       "      <th>var_062_orient</th>\n",
       "      <th>var_062_pochta</th>\n",
       "      <th>var_062_renaissance</th>\n",
       "      <th>var_062_rosbank</th>\n",
       "      <th>var_062_sbrf</th>\n",
       "      <th>var_062_tinkoff</th>\n",
       "      <th>var_062_ubrr</th>\n",
       "      <th>var_062_uralsib</th>\n",
       "      <th>var_062_vtb24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.167919</td>\n",
       "      <td>0.673893</td>\n",
       "      <td>-0.767992</td>\n",
       "      <td>-0.073527</td>\n",
       "      <td>1.374671</td>\n",
       "      <td>-0.070758</td>\n",
       "      <td>-0.480494</td>\n",
       "      <td>-0.125601</td>\n",
       "      <td>0.655862</td>\n",
       "      <td>-0.166119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046598</td>\n",
       "      <td>-0.058819</td>\n",
       "      <td>-0.137902</td>\n",
       "      <td>-0.035815</td>\n",
       "      <td>-0.126636</td>\n",
       "      <td>0.655344</td>\n",
       "      <td>-0.087093</td>\n",
       "      <td>-0.087736</td>\n",
       "      <td>-0.141723</td>\n",
       "      <td>-0.360996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.167919</td>\n",
       "      <td>0.673893</td>\n",
       "      <td>-0.767992</td>\n",
       "      <td>-0.073527</td>\n",
       "      <td>-0.727447</td>\n",
       "      <td>-0.070758</td>\n",
       "      <td>-0.480494</td>\n",
       "      <td>-0.125601</td>\n",
       "      <td>0.655862</td>\n",
       "      <td>-0.166119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046598</td>\n",
       "      <td>-0.058819</td>\n",
       "      <td>-0.137902</td>\n",
       "      <td>-0.035815</td>\n",
       "      <td>-0.126636</td>\n",
       "      <td>0.655344</td>\n",
       "      <td>-0.087093</td>\n",
       "      <td>-0.087736</td>\n",
       "      <td>-0.141723</td>\n",
       "      <td>-0.360996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.167919</td>\n",
       "      <td>0.673893</td>\n",
       "      <td>-0.767992</td>\n",
       "      <td>-0.073527</td>\n",
       "      <td>-0.727447</td>\n",
       "      <td>-0.070758</td>\n",
       "      <td>-0.480494</td>\n",
       "      <td>-0.125601</td>\n",
       "      <td>0.655862</td>\n",
       "      <td>-0.166119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046598</td>\n",
       "      <td>-0.058819</td>\n",
       "      <td>-0.137902</td>\n",
       "      <td>-0.035815</td>\n",
       "      <td>-0.126636</td>\n",
       "      <td>0.655344</td>\n",
       "      <td>-0.087093</td>\n",
       "      <td>-0.087736</td>\n",
       "      <td>-0.141723</td>\n",
       "      <td>-0.360996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.167919</td>\n",
       "      <td>0.673893</td>\n",
       "      <td>-0.767992</td>\n",
       "      <td>-0.073527</td>\n",
       "      <td>1.374671</td>\n",
       "      <td>-0.070758</td>\n",
       "      <td>-0.480494</td>\n",
       "      <td>-0.125601</td>\n",
       "      <td>0.655862</td>\n",
       "      <td>-0.166119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046598</td>\n",
       "      <td>-0.058819</td>\n",
       "      <td>-0.137902</td>\n",
       "      <td>-0.035815</td>\n",
       "      <td>-0.126636</td>\n",
       "      <td>-1.525916</td>\n",
       "      <td>-0.087093</td>\n",
       "      <td>-0.087736</td>\n",
       "      <td>-0.141723</td>\n",
       "      <td>2.770113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.167919</td>\n",
       "      <td>-1.483916</td>\n",
       "      <td>-0.767992</td>\n",
       "      <td>-0.073527</td>\n",
       "      <td>-0.727447</td>\n",
       "      <td>-0.070758</td>\n",
       "      <td>-0.480494</td>\n",
       "      <td>-0.125601</td>\n",
       "      <td>-1.524711</td>\n",
       "      <td>-0.166119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046598</td>\n",
       "      <td>-0.058819</td>\n",
       "      <td>-0.137902</td>\n",
       "      <td>-0.035815</td>\n",
       "      <td>-0.126636</td>\n",
       "      <td>0.655344</td>\n",
       "      <td>-0.087093</td>\n",
       "      <td>-0.087736</td>\n",
       "      <td>-0.141723</td>\n",
       "      <td>-0.360996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 471 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    var_001   var_002   var_003   var_004   var_005   var_006   var_007  \\\n",
       "0 -0.167919  0.673893 -0.767992 -0.073527  1.374671 -0.070758 -0.480494   \n",
       "1 -0.167919  0.673893 -0.767992 -0.073527 -0.727447 -0.070758 -0.480494   \n",
       "2 -0.167919  0.673893 -0.767992 -0.073527 -0.727447 -0.070758 -0.480494   \n",
       "3 -0.167919  0.673893 -0.767992 -0.073527  1.374671 -0.070758 -0.480494   \n",
       "4 -0.167919 -1.483916 -0.767992 -0.073527 -0.727447 -0.070758 -0.480494   \n",
       "\n",
       "    var_008   var_009   var_010  ...  var_062_mts  var_062_orient  \\\n",
       "0 -0.125601  0.655862 -0.166119  ...    -0.046598       -0.058819   \n",
       "1 -0.125601  0.655862 -0.166119  ...    -0.046598       -0.058819   \n",
       "2 -0.125601  0.655862 -0.166119  ...    -0.046598       -0.058819   \n",
       "3 -0.125601  0.655862 -0.166119  ...    -0.046598       -0.058819   \n",
       "4 -0.125601 -1.524711 -0.166119  ...    -0.046598       -0.058819   \n",
       "\n",
       "   var_062_pochta  var_062_renaissance  var_062_rosbank  var_062_sbrf  \\\n",
       "0       -0.137902            -0.035815        -0.126636      0.655344   \n",
       "1       -0.137902            -0.035815        -0.126636      0.655344   \n",
       "2       -0.137902            -0.035815        -0.126636      0.655344   \n",
       "3       -0.137902            -0.035815        -0.126636     -1.525916   \n",
       "4       -0.137902            -0.035815        -0.126636      0.655344   \n",
       "\n",
       "   var_062_tinkoff  var_062_ubrr  var_062_uralsib  var_062_vtb24  \n",
       "0        -0.087093     -0.087736        -0.141723      -0.360996  \n",
       "1        -0.087093     -0.087736        -0.141723      -0.360996  \n",
       "2        -0.087093     -0.087736        -0.141723      -0.360996  \n",
       "3        -0.087093     -0.087736        -0.141723       2.770113  \n",
       "4        -0.087093     -0.087736        -0.141723      -0.360996  \n",
       "\n",
       "[5 rows x 471 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63230, 471)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y2, test_size=0.3, stratify=y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.float()\n",
    "X_test = X_test.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderNet, self).__init__()\n",
    "        self.bn0 = torch.nn.BatchNorm1d(471)\n",
    "        self.fc1 = torch.nn.Linear(471, 235)\n",
    "        self.ac1 = torch.nn.ReLU()\n",
    "        self.bn1 = torch.nn.BatchNorm1d(235)\n",
    "        self.fc2 = torch.nn.Linear(235, 117)\n",
    "        self.ac2 = torch.nn.ReLU()\n",
    "        self.bn2 = torch.nn.BatchNorm1d(117)\n",
    "        self.fc3 = torch.nn.Linear(117, 60)\n",
    "        self.ac3 = torch.nn.ReLU()\n",
    "        self.bn3 = torch.nn.BatchNorm1d(60)\n",
    "        self.fc4 = torch.nn.Linear(60, 117)\n",
    "        self.ac4 = torch.nn.ReLU()\n",
    "        self.bn4 = torch.nn.BatchNorm1d(117)\n",
    "        self.fc5 = torch.nn.Linear(117, 235)\n",
    "        self.ac5 = torch.nn.ReLU()\n",
    "        self.bn5 = torch.nn.BatchNorm1d(235)\n",
    "        self.fc6 = torch.nn.Linear(235, 471)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ac2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ac3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.ac4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.ac5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = self.bn0(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.ac1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.ac2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.ac3(x)\n",
    "        x = self.bn3(x)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, x):\n",
    "        x = self.fc4(x)\n",
    "        x = self.ac4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.ac5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net = EncoderNet()\n",
    "net = net.to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=3.0e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6699)\n",
      "tensor(0.6074)\n",
      "tensor(0.5740)\n",
      "tensor(0.5509)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-afb0370e9d08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mX_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_index\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mstart_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-2baaeeb4e426>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mac5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc6\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   1654\u001b[0m     return torch.batch_norm(\n\u001b[0;32m   1655\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1656\u001b[1;33m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1657\u001b[0m     )\n\u001b[0;32m   1658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "loss_history = []\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(1000):\n",
    "    order = numpy.random.permutation(len(X_train))\n",
    "    for start_index in range(0, len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        X_batch = X_train[order[start_index : start_index + batch_size]]\n",
    "        preds = net.forward(X_batch)\n",
    "        loss_val = loss(preds, X_batch)\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_pred = net.forward(X_test)\n",
    "    loss_history.append((loss(test_pred, X_test).data))\n",
    "    print(loss_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bf87260cf8>]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type EncoderNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net, 'encoder.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_en = net.encode(X_train).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_en = net.encode(X_test).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_en = X_train_en.numpy()\n",
    "X_test_en = X_test_en.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-173-61172776050e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "y_train = y_train.numpy()\n",
    "y_test = y_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {'alpha': [10 ** a for a in range(-6, -1)]}\n",
    "clf = GridSearchCV(SGDClassifier(loss='log', penalty='l2')\n",
    "                  ,tuned_parameters, cv=9, scoring='roc_auc').fit(X_train_en, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6285241903510304"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test_en, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.01      0.01      6095\n",
      "           1       0.68      1.00      0.81     12874\n",
      "\n",
      "    accuracy                           0.68     18969\n",
      "   macro avg       0.61      0.50      0.41     18969\n",
      "weighted avg       0.64      0.68      0.55     18969\n",
      "\n",
      "0.5020429217213905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
